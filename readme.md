# My Github Project
## Project: The Art Collaborator
### Hi, my name is Debjyoti Bhowmick. I am a Digital Game Design student at the National Institute of Design, Bangalore. This is the Atelier project for my Exchange Program in Media Design at HEAD, Geneva.

## Devlog

### 23.10.20
#### The aim of this project is to create a playful AI assistant like experience either in an exhibition or a product design context attuned for beginner/ amateur artists. Exploring ways to use user emotions to have the AI create and print art for the user to collaborate with.

### 23.10.25
#### Currently thinking of fixed emotional states to choose from to denote a set variety of emotions to create with. I am hoping to translate these inputs into line weights/ thicknesses to create randomised artwork outputs. This idea shows promise.

### 23.10.30
### ![Prototype 1-1](https://github.com/Debjyoti001/head-md1-future-of-drawing/assets/149476943/d73bc2cd-82df-42b3-86f4-33b13158e286)
#### Today was the first prototype test day. My prototype focused on inputs from three emotional states but Alexia had a comment that stuck with me "Is there any emotional expression option for me, pregnant and tired?" Most of the other testing went fine but now I am wondering whether fixed emotional states to choose from is really a good option if I want the user to be able to connect with the experience I am building.  
#### The gist of my research until this point has been linked herewith:
#### [Research Update_30.10.23.pdf](https://github.com/Debjyoti001/head-md1-future-of-drawing/files/13962364/Research.Update_30.10.23.pdf)
#### Another problem I have run into is with the projected user journey.
#### ![Screenshot 2024-01-17 121916](https://github.com/Debjyoti001/head-md1-future-of-drawing/assets/149476943/b55845c9-af5e-4917-9cfc-0f5f59f2d81f)
#### I received unanimous feedback that I am trying to target too wide of a target audience. Douglas said that a good product can be not for everyone, we must pick our battles.


### 23.11.5
#### ![Screenshot 2024-01-17 115718](https://github.com/Debjyoti001/head-md1-future-of-drawing/assets/149476943/d5f96bff-ed23-4e90-b066-a8c4cbd9ac17)
#### ![Screenshot 2024-01-17 115755](https://github.com/Debjyoti001/head-md1-future-of-drawing/assets/149476943/cf188fe9-4027-4050-95e1-5b77c3370458)
#### Last prototype update was a few days ago. Have no been able to definitively solve the problem with user input for a variety of emotional spectrums yet. Thinkng of implementing emotional slider input methods into the user expereince to allow for the 'device' to recognise a wide variety of emotional inputs. Hoping this idea works out.


